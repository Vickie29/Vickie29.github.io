{"title":"教女朋友学会用 win10+yolov3+python 训练自己的模型","slug":"教女朋友学会用win10+yolov3+python训练自己的模型","date":"2020-06-17","updated":"2020-06-17","comments":true,"path":"api/posts/63366.json","excerpt":"<blockquote><p>times：2020/3/23<br>操作系统：win10<br>环境：python 3.6<br>因为我之前把所有内容写在一篇文章里非常的乱，所以本文主线是训练自己的 yolo.h5 去识别图像中的人，所有小细节的操作，我都在文中添加了链接，新手的话需要注意看一下。<br>// 有任何的问题都可以直接评论，还有资料的话直接留言邮箱，说明问题 //<br>// 也可以评论下加下微信询问 //<br>大家一起加油学习 yolo，之后我会再出一篇详细介绍 yolo 代码的文章 <br> 新创建的小小交流群：977947271 想要资料的也可以在群里要哦<br>2020/5/30：</p></blockquote><p>如果你是 yolo 小白，或者环境配置等一直报错，请先参阅上一篇博文：<a href=\"https://blog.csdn.net/qq_45504119/article/details/105033492\" target=\"_blank\" rel=\"noopener\">keras-yolov3 目标检测详解——适合新手</a> (环境配置、用官方权重识别自己的图片)</p>","cover":"https://img-blog.csdnimg.cn/20200323190223242.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","covers":["https://img-blog.csdnimg.cn/20200323190223242.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323194549165.png","https://img-blog.csdnimg.cn/20200323201423401.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323195853955.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323200108855.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323200132768.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323200159422.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323201211208.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/2020032320220362.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323203028861.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323203328943.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323213806877.png","https://img-blog.csdnimg.cn/20200323203712506.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323203936905.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323203955552.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323205031301.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/202003232052127.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323205103807.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323213125140.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323213046688.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/2020032321335393.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/2020032321563349.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323220016562.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323220244528.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323220350578.png","https://img-blog.csdnimg.cn/20200323221119292.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70","https://img-blog.csdnimg.cn/20200323221200911.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70"],"content":"<blockquote>\n<p>times：2020/3/23<br>操作系统：win10<br>环境：python 3.6<br>因为我之前把所有内容写在一篇文章里非常的乱，所以本文主线是训练自己的 yolo.h5 去识别图像中的人，所有小细节的操作，我都在文中添加了链接，新手的话需要注意看一下。<br>// 有任何的问题都可以直接评论，还有资料的话直接留言邮箱，说明问题 //<br>// 也可以评论下加下微信询问 //<br>大家一起加油学习 yolo，之后我会再出一篇详细介绍 yolo 代码的文章 <br> 新创建的小小交流群：977947271 想要资料的也可以在群里要哦<br>2020/5/30：</p>\n</blockquote>\n<p>如果你是 yolo 小白，或者环境配置等一直报错，请先参阅上一篇博文：<a href=\"https://blog.csdn.net/qq_45504119/article/details/105033492\" target=\"_blank\" rel=\"noopener\">keras-yolov3 目标检测详解——适合新手</a> (环境配置、用官方权重识别自己的图片)</p>\n<a id=\"more\"></a>\n<h2 id=\"本文目的：\"><a href=\"# 本文目的：\" class=\"headerlink\" title=\"本文目的：\"></a>本文目的：</h2><p>前面有篇文章说的是利用官方的权重直接识别自己的图片，我也展示了识别的效果。</p>\n<p>今天我介绍一下如何创建自己的数据集去训练属于自己的 <code>model</code></p>\n<h2 id=\"前提准备：\"><a href=\"# 前提准备：\" class=\"headerlink\" title=\"前提准备：\"></a>前提准备：</h2><p><strong>1、配置好环境的 python、anaconda 或 pycharm</strong></p>\n<p><strong>2、labelimg 软件：下载方法：</strong> <a href=\"https://blog.csdn.net/qq_45504119/article/details/105038483\" target=\"_blank\" rel=\"noopener\">labelimg 的下载与使用</a></p>\n<p><strong>3、准备一些图片，创建训练需要的 VOC 文件</strong></p>\n<p><strong>（1）</strong> 官方的 VOC2007 下载链接：<a href=\"http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\" target=\"_blank\" rel=\"noopener\">voc2007 下载链接</a>，可以从这里找需要的图片，或者一些有基础的朋友可以写爬虫去爬一些图片</p>\n<p><strong>（2）</strong> voc2007 百度网盘下载链接：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">链接：https:<span class=\"comment\">//pan.baidu.com/s/18wqRTZDSz5NQEtvq0u0a1g </span></span><br><span class=\"line\">提取码：hexy</span><br></pre></td></tr></table></figure>\n<p><strong>（3）</strong> 可以自己准备图片，不过最好准备多一点<br>.<br>.</p>\n<h2 id=\"正式训练步骤：\"><a href=\"# 正式训练步骤：\" class=\"headerlink\" title=\"正式训练步骤：\"></a>正式训练步骤：</h2><p><strong>一、准备自己的 voc2007 数据集</strong></p>\n<p>先用 pycharm 或 spyder 打开 keras-yolo3 文件夹，用 pycharm 或 spyder 是为了看文件夹更方便，直接在 anaconda 里运行也是可以的</p>\n<p><strong>1、打开文件夹</strong></p>\n<p>先按照这篇文章的步骤操作：<a href=\"https://blog.csdn.net/qq_45504119/article/details/105033492\" target=\"_blank\" rel=\"noopener\">keras-yolov3 目标检测详解——适合新手</a></p>\n<p>完成后打开的文件夹应该是这样的：</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323190223242.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><strong>2、新建 voc2007 数据集（存放自己的图片及标注信息）</strong></p>\n<p>新建的文件夹：如下</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323194549165.png\" alt=\"在这里插入图片描述\"></p>\n<p><code>ImageSets</code> 文件夹下还有个名为  <code>Main</code>  的小文件夹</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323201423401.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">VOCdevkit&#123;</span><br><span class=\"line\">\t\t\tVOC2007&#123;\tAnnotations</span><br><span class=\"line\">\t\t\t\t\t\tImageSets&#123;main&#125;</span><br><span class=\"line\">\t\t\t\t\t\tJPEGImages\t&#125;\t\t\t\t</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t&#125;</span><br><span class=\"line\">虽然表达的很丑，但是上面有图，应该还是可以看明白的 </span><br><span class=\"line\"> 注意：文件夹的名称必须和上面展示的一样，这是 yolo 默认的</span><br><span class=\"line\">\t  不然还需要改代码才行</span><br></pre></td></tr></table></figure>\n\n<p><strong>3、用 labelimg 软件对自己的图片进行信息标注</strong></p>\n<p>—-<strong>labelimg 的使用方法：</strong><a href=\"https://blog.csdn.net/qq_45504119/article/details/105038483\" target=\"_blank\" rel=\"noopener\">labelimg 下载和标注 xlm 文件</a></p>\n<blockquote>\n<p>想要训练自己的模型就要学会 labelimg 的使用，实在不想学的…就评论一下邮箱，我直接把我标注好的 VOC2007 文件夹打包发给你们吧</p>\n</blockquote>\n<p>（1）需要训练的图片放在 <code>JPEGImages</code> 里面：</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323195853955.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323200108855.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>（2）labelimg 标注的 xlm 文件放在 <code>Annotations</code> 里面：</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323200132768.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323200159422.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><strong>4、在 VOC2007  里新建一个 py 文件</strong></p>\n<p><strong>我这里取名 voc.py</strong></p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323201211208.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><strong>voc.py 的代码：</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"></span><br><span class=\"line\">trainval_percent = <span class=\"number\">0.2</span> <span class=\"comment\"># 测试集占 0.2</span></span><br><span class=\"line\">train_percent = <span class=\"number\">0.8</span>    <span class=\"comment\"># 训练集占 0.8</span></span><br><span class=\"line\">xmlfilepath = <span class=\"string\">'Annotations'</span></span><br><span class=\"line\">txtsavepath = <span class=\"string\">'ImageSets\\Main'</span></span><br><span class=\"line\">total_xml = os.listdir(xmlfilepath)</span><br><span class=\"line\"></span><br><span class=\"line\">num = len(total_xml)</span><br><span class=\"line\">list = range(num)</span><br><span class=\"line\">tv = int(num * trainval_percent)</span><br><span class=\"line\">tr = int(tv * train_percent)</span><br><span class=\"line\">trainval = random.sample(list, tv)</span><br><span class=\"line\">train = random.sample(trainval, tr)</span><br><span class=\"line\"></span><br><span class=\"line\">ftrainval = open(<span class=\"string\">'ImageSets/Main/trainval.txt'</span>, <span class=\"string\">'w'</span>)</span><br><span class=\"line\">ftest = open(<span class=\"string\">'ImageSets/Main/test.txt'</span>, <span class=\"string\">'w'</span>)</span><br><span class=\"line\">ftrain = open(<span class=\"string\">'ImageSets/Main/train.txt'</span>, <span class=\"string\">'w'</span>)</span><br><span class=\"line\">fval = open(<span class=\"string\">'ImageSets/Main/val.txt'</span>, <span class=\"string\">'w'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> list:</span><br><span class=\"line\">    name = total_xml[i][:<span class=\"number\">-4</span>] + <span class=\"string\">'\\n'</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> i <span class=\"keyword\">in</span> trainval:</span><br><span class=\"line\">        ftrainval.write(name)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> i <span class=\"keyword\">in</span> train:</span><br><span class=\"line\">            ftest.write(name)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            fval.write(name)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        ftrain.write(name)</span><br><span class=\"line\"></span><br><span class=\"line\">ftrainval.close()</span><br><span class=\"line\">ftrain.close()</span><br><span class=\"line\">fval.close()</span><br><span class=\"line\">ftest.close()</span><br><span class=\"line\">直接复制以上代码即可</span><br></pre></td></tr></table></figure>\n<p><strong>然后运行 voc.py 文件</strong></p>\n<p><strong>运行成功的话 mian 文件夹里会多了四个 txt 文件</strong></p>\n<p><img src=\"https://img-blog.csdnimg.cn/2020032320220362.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><strong>完成以上所有步骤，VOC 的处理就完成了</strong></p>\n<p>.</p>\n<p><strong>二、进行训练前的最后准备</strong></p>\n<p><strong>1、修改 <code>voc_annotation.py</code> 文件并运行</strong></p>\n<p>更改这里的  classes 的数量，你 voc2007 里标注了哪几种，你就留哪几种就行</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323203028861.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>比如我的 voc 中只标注了 “person”，那我只留下“person”，然后再运行一下就行</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323203328943.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>运行完成后会多出这几个 txt 文件</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323213806877.png\" alt=\"在这里插入图片描述\"></p>\n<p><strong>2、修改 model_data</strong></p>\n<p>将 coco_classes.txt 和 voc_classes.txt 中也只留下 VOC2007 中所标注的那个类型</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323203712506.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>比如我标注的只有 “person”</p>\n<p>那我只留下“person”</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323203936905.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323203955552.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><strong>3、修改 yolo3.cfg</strong></p>\n<p>大概在 610、696 和 783 行的位置，把 classes 的数值都改为 1</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323205031301.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><img src=\"https://img-blog.csdnimg.cn/202003232052127.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323205103807.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>4、添加官方权重</strong></p>\n<p>按照上篇博文步骤进行的朋友应该下载好了 <code>yolov3.weights</code> 文件并转为了 <code>yolo.h5</code> 文件</p>\n<p>附上上篇博文的链接（里面有下载链接和转化方法）：<a href=\"https://blog.csdn.net/qq_45504119/article/details/105033492\" target=\"_blank\" rel=\"noopener\">keras-yolov3 目标检测详解——适合新手</a></p>\n<p>将 <code>yolo.h5</code> 改名为 <code>yolo_weights.h5</code></p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323213125140.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323213046688.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><strong>5、新建 logs 文件夹存放训练的 权重文件</strong></p>\n<p><img src=\"https://img-blog.csdnimg.cn/2020032321335393.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><strong>6、开始训练</strong></p>\n<p>在 <code>keras-yolo3-master</code> 文件夹下新建 一个名为 <code>trainyolo.py</code>  的文件</p>\n<p>为什么不用 源文件中的 train.py 呢？？（因为我运行的时候一直出现库的报错…建议按照我的方法来）</p>\n<p><code>trainyolo.py</code> 的代码(直接复制即可)：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">import</span> keras.backend <span class=\"keyword\">as</span> K</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> Input, Lambda</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.models <span class=\"keyword\">import</span> Model</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.optimizers <span class=\"keyword\">import</span> Adam</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.callbacks <span class=\"keyword\">import</span> TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping</span><br><span class=\"line\"><span class=\"keyword\">from</span> yolo3.model <span class=\"keyword\">import</span> yolo_body</span><br><span class=\"line\"><span class=\"keyword\">from</span> yolo3.model <span class=\"keyword\">import</span> yolo_loss</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.backend.tensorflow_backend <span class=\"keyword\">import</span> set_session</span><br><span class=\"line\"><span class=\"keyword\">from</span> yolo3.utils <span class=\"keyword\">import</span> get_random_data</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_classes</span><span class=\"params\">(classes_path)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">'''loads the classes'''</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(classes_path) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        class_names = f.readlines()</span><br><span class=\"line\">    class_names = [c.strip() <span class=\"keyword\">for</span> c <span class=\"keyword\">in</span> class_names]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> class_names</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_anchors</span><span class=\"params\">(anchors_path)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">'''loads the anchors from a file'''</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(anchors_path) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        anchors = f.readline()</span><br><span class=\"line\">    anchors = [float(x) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> anchors.split(<span class=\"string\">','</span>)]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.array(anchors).reshape(<span class=\"number\">-1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">data_generator</span><span class=\"params\">(annotation_lines, batch_size, input_shape, anchors, num_classes)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">'''data generator for fit_generator'''</span></span><br><span class=\"line\">    n = len(annotation_lines)</span><br><span class=\"line\">    i = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">        image_data = []</span><br><span class=\"line\">        box_data = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> range(batch_size):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> i==<span class=\"number\">0</span>:</span><br><span class=\"line\">                np.random.shuffle(annotation_lines)</span><br><span class=\"line\">            image, box = get_random_data(annotation_lines[i], input_shape, random=<span class=\"literal\">True</span>)</span><br><span class=\"line\">            image_data.append(image)</span><br><span class=\"line\">            box_data.append(box)</span><br><span class=\"line\">            i = (i+<span class=\"number\">1</span>) % n</span><br><span class=\"line\">        image_data = np.array(image_data)</span><br><span class=\"line\">        box_data = np.array(box_data)</span><br><span class=\"line\">        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> [image_data, *y_true], np.zeros(batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">preprocess_true_boxes</span><span class=\"params\">(true_boxes, input_shape, anchors, num_classes)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (true_boxes[..., <span class=\"number\">4</span>]&lt;num_classes).all(), <span class=\"string\">'class id must be less than num_classes'</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    num_layers = len(anchors)//<span class=\"number\">3</span> </span><br><span class=\"line\">    anchor_mask = [[<span class=\"number\">6</span>,<span class=\"number\">7</span>,<span class=\"number\">8</span>], [<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>], [<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>]] <span class=\"keyword\">if</span> num_layers==<span class=\"number\">3</span> <span class=\"keyword\">else</span> [[<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>], [<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\">    true_boxes = np.array(true_boxes, dtype=<span class=\"string\">'float32'</span>)</span><br><span class=\"line\">    input_shape = np.array(input_shape, dtype=<span class=\"string\">'int32'</span>) <span class=\"comment\"># 416,416</span></span><br><span class=\"line\">    boxes_xy = (true_boxes[..., <span class=\"number\">0</span>:<span class=\"number\">2</span>] + true_boxes[..., <span class=\"number\">2</span>:<span class=\"number\">4</span>]) // <span class=\"number\">2</span></span><br><span class=\"line\">    boxes_wh = true_boxes[..., <span class=\"number\">2</span>:<span class=\"number\">4</span>] - true_boxes[..., <span class=\"number\">0</span>:<span class=\"number\">2</span>]</span><br><span class=\"line\">    true_boxes[..., <span class=\"number\">0</span>:<span class=\"number\">2</span>] = boxes_xy/input_shape[:]</span><br><span class=\"line\">    true_boxes[..., <span class=\"number\">2</span>:<span class=\"number\">4</span>] = boxes_wh/input_shape[:]</span><br><span class=\"line\"></span><br><span class=\"line\">    m = true_boxes.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    grid_shapes = [input_shape//&#123;<span class=\"number\">0</span>:<span class=\"number\">32</span>, <span class=\"number\">1</span>:<span class=\"number\">16</span>, <span class=\"number\">2</span>:<span class=\"number\">8</span>&#125;[l] <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(num_layers)]</span><br><span class=\"line\">    y_true = [np.zeros((m,grid_shapes[l][<span class=\"number\">0</span>],grid_shapes[l][<span class=\"number\">1</span>],len(anchor_mask[l]),<span class=\"number\">5</span>+num_classes),</span><br><span class=\"line\">        dtype=<span class=\"string\">'float32'</span>) <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(num_layers)]</span><br><span class=\"line\">    anchors = np.expand_dims(anchors, <span class=\"number\">0</span>)</span><br><span class=\"line\">    anchor_maxes = anchors / <span class=\"number\">2.</span></span><br><span class=\"line\">    anchor_mins = -anchor_maxes</span><br><span class=\"line\">    valid_mask = boxes_wh[..., <span class=\"number\">0</span>]&gt;<span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> range(m):</span><br><span class=\"line\">        wh = boxes_wh[b, valid_mask[b]]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> len(wh)==<span class=\"number\">0</span>: <span class=\"keyword\">continue</span></span><br><span class=\"line\">        wh = np.expand_dims(wh, <span class=\"number\">-2</span>)</span><br><span class=\"line\">        box_maxes = wh / <span class=\"number\">2.</span></span><br><span class=\"line\">        box_mins = -box_maxes</span><br><span class=\"line\"></span><br><span class=\"line\">        intersect_mins = np.maximum(box_mins, anchor_mins)</span><br><span class=\"line\">        intersect_maxes = np.minimum(box_maxes, anchor_maxes)</span><br><span class=\"line\">        intersect_wh = np.maximum(intersect_maxes - intersect_mins, <span class=\"number\">0.</span>)</span><br><span class=\"line\">        intersect_area = intersect_wh[..., <span class=\"number\">0</span>] * intersect_wh[..., <span class=\"number\">1</span>]</span><br><span class=\"line\">        box_area = wh[..., <span class=\"number\">0</span>] * wh[..., <span class=\"number\">1</span>]</span><br><span class=\"line\">        anchor_area = anchors[..., <span class=\"number\">0</span>] * anchors[..., <span class=\"number\">1</span>]</span><br><span class=\"line\">        iou = intersect_area / (box_area + anchor_area - intersect_area)</span><br><span class=\"line\">        best_anchor = np.argmax(iou, axis=<span class=\"number\">-1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> t, n <span class=\"keyword\">in</span> enumerate(best_anchor):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(num_layers):</span><br><span class=\"line\">                <span class=\"keyword\">if</span> n <span class=\"keyword\">in</span> anchor_mask[l]:</span><br><span class=\"line\">                    i = np.floor(true_boxes[b,t,<span class=\"number\">0</span>]*grid_shapes[l][<span class=\"number\">1</span>]).astype(<span class=\"string\">'int32'</span>)</span><br><span class=\"line\">                    j = np.floor(true_boxes[b,t,<span class=\"number\">1</span>]*grid_shapes[l][<span class=\"number\">0</span>]).astype(<span class=\"string\">'int32'</span>)</span><br><span class=\"line\">                    k = anchor_mask[l].index(n)</span><br><span class=\"line\">                    c = true_boxes[b,t, <span class=\"number\">4</span>].astype(<span class=\"string\">'int32'</span>)</span><br><span class=\"line\">                    y_true[l][b, j, i, k, <span class=\"number\">0</span>:<span class=\"number\">4</span>] = true_boxes[b,t, <span class=\"number\">0</span>:<span class=\"number\">4</span>]</span><br><span class=\"line\">                    y_true[l][b, j, i, k, <span class=\"number\">4</span>] = <span class=\"number\">1</span></span><br><span class=\"line\">                    y_true[l][b, j, i, k, <span class=\"number\">5</span>+c] = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> y_true</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">config = tf.ConfigProto()</span><br><span class=\"line\">config.gpu_options.allocator_type = <span class=\"string\">'BFC'</span></span><br><span class=\"line\">config.gpu_options.per_process_gpu_memory_fraction = <span class=\"number\">0.7</span></span><br><span class=\"line\">config.gpu_options.allow_growth = <span class=\"literal\">True</span></span><br><span class=\"line\">set_session(tf.Session(config=config)) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    annotation_path = <span class=\"string\">'2007_train.txt'</span></span><br><span class=\"line\">    classes_path = <span class=\"string\">'model_data/voc_classes.txt'</span>    </span><br><span class=\"line\">    anchors_path = <span class=\"string\">'model_data/yolo_anchors.txt'</span></span><br><span class=\"line\">    weights_path = <span class=\"string\">'model_data/yolo_weights.h5'</span></span><br><span class=\"line\">    class_names = get_classes(classes_path)</span><br><span class=\"line\">    anchors = get_anchors(anchors_path)</span><br><span class=\"line\">    num_classes = len(class_names)</span><br><span class=\"line\">    num_anchors = len(anchors)</span><br><span class=\"line\">    log_dir = <span class=\"string\">'logs/'</span></span><br><span class=\"line\">    input_shape = (<span class=\"number\">416</span>,<span class=\"number\">416</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    K.clear_session()</span><br><span class=\"line\"></span><br><span class=\"line\">    image_input = Input(shape=(<span class=\"literal\">None</span>, <span class=\"literal\">None</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\">    h, w = input_shape</span><br><span class=\"line\"></span><br><span class=\"line\">    print(<span class=\"string\">'Create YOLOv3 model with &#123;&#125; anchors and &#123;&#125; classes.'</span>.format(num_anchors, num_classes))</span><br><span class=\"line\">    model_body = yolo_body(image_input, num_anchors//<span class=\"number\">3</span>, num_classes)</span><br><span class=\"line\">    </span><br><span class=\"line\">    print(<span class=\"string\">'Load weights &#123;&#125;.'</span>.format(weights_path))</span><br><span class=\"line\">    model_body.load_weights(weights_path, by_name=<span class=\"literal\">True</span>, skip_mismatch=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    y_true = [Input(shape=(h//&#123;<span class=\"number\">0</span>:<span class=\"number\">32</span>, <span class=\"number\">1</span>:<span class=\"number\">16</span>, <span class=\"number\">2</span>:<span class=\"number\">8</span>&#125;[l], w//&#123;<span class=\"number\">0</span>:<span class=\"number\">32</span>, <span class=\"number\">1</span>:<span class=\"number\">16</span>, <span class=\"number\">2</span>:<span class=\"number\">8</span>&#125;[l], \\</span><br><span class=\"line\">        num_anchors//<span class=\"number\">3</span>, num_classes+<span class=\"number\">5</span>)) <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(<span class=\"number\">3</span>)]</span><br><span class=\"line\"></span><br><span class=\"line\">    loss_input = [*model_body.output, *y_true]</span><br><span class=\"line\">    model_loss = Lambda(yolo_loss, output_shape=(<span class=\"number\">1</span>,), name=<span class=\"string\">'yolo_loss'</span>,</span><br><span class=\"line\">        arguments=&#123;<span class=\"string\">'anchors'</span>: anchors, <span class=\"string\">'num_classes'</span>: num_classes, <span class=\"string\">'ignore_thresh'</span>: <span class=\"number\">0.5</span>&#125;)(loss_input)</span><br><span class=\"line\"></span><br><span class=\"line\">    model = Model([model_body.input, *y_true], model_loss)</span><br><span class=\"line\"></span><br><span class=\"line\">    freeze_layers = <span class=\"number\">249</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(freeze_layers): model_body.layers[i].trainable = <span class=\"literal\">False</span></span><br><span class=\"line\">    print(<span class=\"string\">'Freeze the first &#123;&#125; layers of total &#123;&#125; layers.'</span>.format(freeze_layers, len(model_body.layers)))</span><br><span class=\"line\"></span><br><span class=\"line\">    logging = TensorBoard(log_dir=log_dir)</span><br><span class=\"line\">    checkpoint = ModelCheckpoint(log_dir + <span class=\"string\">'ep&#123;epoch:03d&#125;-loss&#123;loss:.3f&#125;-val_loss&#123;val_loss:.3f&#125;.h5'</span>,</span><br><span class=\"line\">        monitor=<span class=\"string\">'val_loss'</span>, save_weights_only=<span class=\"literal\">True</span>, save_best_only=<span class=\"literal\">False</span>, period=<span class=\"number\">2</span>)</span><br><span class=\"line\">    reduce_lr = ReduceLROnPlateau(monitor=<span class=\"string\">'val_loss'</span>, factor=<span class=\"number\">0.5</span>, patience=<span class=\"number\">2</span>, verbose=<span class=\"number\">1</span>)</span><br><span class=\"line\">    early_stopping = EarlyStopping(monitor=<span class=\"string\">'val_loss'</span>, min_delta=<span class=\"number\">0</span>, patience=<span class=\"number\">6</span>, verbose=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    val_split = <span class=\"number\">0.2</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(annotation_path) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        lines = f.readlines()</span><br><span class=\"line\">    np.random.seed(<span class=\"number\">10101</span>)</span><br><span class=\"line\">    np.random.shuffle(lines)</span><br><span class=\"line\">    np.random.seed(<span class=\"literal\">None</span>)</span><br><span class=\"line\">    num_val = int(len(lines)*val_split)</span><br><span class=\"line\">    num_train = len(lines) - num_val</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">        model.compile(optimizer=Adam(lr=<span class=\"number\">1e-3</span>), loss=&#123;</span><br><span class=\"line\">            <span class=\"string\">'yolo_loss'</span>: <span class=\"keyword\">lambda</span> y_true, y_pred: y_pred&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">        batch_size = <span class=\"number\">1</span></span><br><span class=\"line\">        print(<span class=\"string\">'Train on &#123;&#125; samples, val on &#123;&#125; samples, with batch size &#123;&#125;.'</span>.format(num_train, num_val, batch_size))</span><br><span class=\"line\">        model.fit_generator(data_generator(lines[:num_train], batch_size, input_shape, anchors, num_classes),</span><br><span class=\"line\">                steps_per_epoch=max(<span class=\"number\">1</span>, num_train//batch_size),</span><br><span class=\"line\">                validation_data=data_generator(lines[num_train:], batch_size, input_shape, anchors, num_classes),</span><br><span class=\"line\">                validation_steps=max(<span class=\"number\">1</span>, num_val//batch_size),</span><br><span class=\"line\">                epochs=<span class=\"number\">50</span>,</span><br><span class=\"line\">                initial_epoch=<span class=\"number\">0</span>,</span><br><span class=\"line\">                callbacks=[logging, checkpoint])</span><br><span class=\"line\">        model.save_weights(log_dir + <span class=\"string\">'trained_weights_stage_1.h5'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(freeze_layers): model_body.layers[i].trainable = <span class=\"literal\">True</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">        model.compile(optimizer=Adam(lr=<span class=\"number\">1e-4</span>), loss=&#123;</span><br><span class=\"line\">            <span class=\"string\">'yolo_loss'</span>: <span class=\"keyword\">lambda</span> y_true, y_pred: y_pred&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">        batch_size = <span class=\"number\">1</span></span><br><span class=\"line\">        print(<span class=\"string\">'Train on &#123;&#125; samples, val on &#123;&#125; samples, with batch size &#123;&#125;.'</span>.format(num_train, num_val, batch_size))</span><br><span class=\"line\">        model.fit_generator(data_generator(lines[:num_train], batch_size, input_shape, anchors, num_classes),</span><br><span class=\"line\">                steps_per_epoch=max(<span class=\"number\">1</span>, num_train//batch_size),</span><br><span class=\"line\">                validation_data=data_generator(lines[num_train:], batch_size, input_shape, anchors, num_classes),</span><br><span class=\"line\">                validation_steps=max(<span class=\"number\">1</span>, num_val//batch_size),</span><br><span class=\"line\">                epochs=<span class=\"number\">100</span>,</span><br><span class=\"line\">                initial_epoch=<span class=\"number\">50</span>,</span><br><span class=\"line\">                callbacks=[logging, checkpoint])</span><br><span class=\"line\">        model.save_weights(log_dir + <span class=\"string\">'last1.h5'</span>)</span><br></pre></td></tr></table></figure>\n<p>然后运行<code>trainyolo.py</code> 的代码</p>\n<p><img src=\"https://img-blog.csdnimg.cn/2020032321563349.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><strong>成功开始训练，训练时间比较长，需要耐心等待</strong></p>\n<p>.<br>.</p>\n<h2 id=\"训练完成：\"><a href=\"# 训练完成：\" class=\"headerlink\" title=\"训练完成：\"></a>训练完成：</h2><p>因为我的电脑配置比较差，所以训练了很长很长时间，这是我前几天训练的结果</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323220016562.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>训练好的权重都放在 logs 文件夹下的 000 文件夹里：</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323220244528.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>按理说训练会经过两个阶段，且自动从一堆 loss 中选则出 loss 最低的文件(应该是 earlystop 函数的作用)：</p>\n<p>应该就是下面的框选的这两个 h5 文件，都可以使用</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323220350578.png\" alt=\"在这里插入图片描述\"></p>\n<p>使用的方法就和前面那篇博文操作一样了（用这个 h5 权重模型去识别自己图片），下面给大家展示一下我训练的模型的结果吧</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323221119292.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200323221200911.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTA0MTE5,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>对比使用官方的权重文件来说，我的模型可以仅仅识别出图片中的人体，而且识别效果还不赖，感觉还不错吧  哈哈哈</p>\n<h2 id=\"总结：\"><a href=\"# 总结：\" class=\"headerlink\" title=\"总结：\"></a>总结：</h2><p>以上过程皆为刚刚我亲自操作，全程没有任何问题</p>\n<p>如果有朋友对这篇文章的任何内容感到不明白的请及时评论提出问题，我怕时间一久我也会忘，想要资料的直接评论你们的联系方式就行，我有时间会回复的。</p>\n<p>这个暂时告一段落，接下来我会在 matlab 中找一些算法去实现同样的功能，有兴趣的朋友可以评论一下一起探讨。</p>\n","url":"/posts/63366/","min2read":11,"word4post":"2.5k","prev_post":{"title":"python 绝对兼容的库配置——机器学习 & 爬虫","url":"/posts/3611/"},"next_post":{"title":"python 绝对兼容的库配置——机器学习","url":"/posts/37357/"},"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" data-id=\"本文目的：\" href = \"#\"><span class=\"toc-number\">1.</span> <span class=\"toc-text\">本文目的：</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" data-id=\"前提准备：\" href = \"#\"><span class=\"toc-number\">2.</span> <span class=\"toc-text\">前提准备：</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" data-id=\"正式训练步骤：\" href = \"#\"><span class=\"toc-number\">3.</span> <span class=\"toc-text\">正式训练步骤：</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" data-id=\"训练完成：\" href = \"#\"><span class=\"toc-number\">4.</span> <span class=\"toc-text\">训练完成：</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" data-id=\"总结：\" href = \"#\"><span class=\"toc-number\">5.</span> <span class=\"toc-text\">总结：</span></a></li></ol>","categories":[{"name":"python","path":"api/categories/python.json","url":"/categories/python/"},{"name":"机器视觉","path":"api/categories/机器视觉.json","url":"/categories/python/机器视觉/"}],"tags":[{"name":"python","path":"api/tags/python.json","url":"/tags/python/"},{"name":"机器视觉","path":"api/tags/机器视觉.json","url":"/tags/机器视觉/"}]}