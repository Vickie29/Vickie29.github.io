{"title":"教女朋友一周学会 python 爬虫_1","slug":"教女朋友一周学会 python 爬虫_1","date":"2020-06-17","updated":"2020-07-08","comments":true,"path":"api/posts/24985.json","excerpt":"<p>今天开始我将简单介绍一下网络爬虫，并开始带大家学习如何写爬虫</p><p><strong>一、爬虫介绍</strong></p><p> <strong>1、什么是爬虫？</strong></p><p>你可以把互联网想想成一个巨大的蜘蛛网，而爬虫就是一个小蜘蛛在网的各个节点中穿梭。   就像探测机器一样，基本操作就是模拟人去浏览各个网站，浏览数据，查看信息。</p>","cover":null,"covers":null,"content":"<p>今天开始我将简单介绍一下网络爬虫，并开始带大家学习如何写爬虫</p>\n<p><strong>一、爬虫介绍</strong></p>\n<p> <strong>1、什么是爬虫？</strong></p>\n<p>你可以把互联网想想成一个巨大的蜘蛛网，而爬虫就是一个小蜘蛛在网的各个节点中穿梭。   就像探测机器一样，基本操作就是模拟人去浏览各个网站，浏览数据，查看信息。</p>\n<a id=\"more\"></a>\n<p> <strong>2、爬虫可以做什么？</strong></p>\n<p><strong>（1）抢火车票：</strong></p>\n<p>这应该是爬虫行业中使用量最大，很多抢票软件每秒对12306扫数千数万次。</p>\n<p><strong>（2）刷浏览量：</strong></p>\n<p>爬虫重灾区应该是微博无疑了，爬虫代码指向微博的某一个接口，可以获取用户的微博列表，微博动态，等等信息。</p>\n<p>有的人用爬虫指挥机器人，来打开某人的微博进行点赞、评论或留言。也就是微博上所谓的僵尸粉（去年某坤微博转发过亿次还记得吗）。</p>\n<p>还有很多更“好玩”的用处，这里就不废话了</p>\n<p><strong>二、正式开始学习</strong></p>\n<p>想写爬虫，首先要了解 URL：</p>\n<p>统一资源定位符（Universal Resource Locator），简单说就是表示资源的地址（我们说某个网站的网址就是 URL）。</p>\n<p><strong>1、urllib.request.urlopen（）函数</strong></p>\n<blockquote>\n<p><strong>urllib 是一个软件包，收集了几个用于处理URL的模块 ：</strong><br>.<br><strong>urllib.request ： 用于打开和阅读URL</strong><br>.<br><strong>urllib.error ： 包含由引发的异常 urllib.request</strong><br>.<br><strong>urllib.parse ： 用于解析URL</strong><br>.<br><strong>urllib.robotparser ： 用于解析robots.txt文件</strong></p>\n</blockquote>\n<p><strong>urllib.request—用于打开URL的可扩展库</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">urllib.request.urlopen（url，data = <span class=\"literal\">None</span>，[ timeout，] *，cafile = <span class=\"literal\">None</span>，capath = <span class=\"literal\">None</span>，cadefault = <span class=\"literal\">False</span>，context = <span class=\"literal\">None</span> ）</span><br><span class=\"line\"><span class=\"comment\">##打开url，字符串或 Request 对象</span></span><br></pre></td></tr></table></figure>\n<p>data：访问URL时传输的数据</p>\n<p>timeout：参数以秒为单位，检测是否超时</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Time：2020/03/11 1:07</span></span><br><span class=\"line\"><span class=\"comment\"># environment:IDLE</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> urllib.request</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>response=urllib.request.urlopen(<span class=\"string\">\"http://www.baidu.com\"</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>type(response)</span><br><span class=\"line\">&lt;<span class=\"class\"><span class=\"keyword\">class</span> '<span class=\"title\">http</span>.<span class=\"title\">client</span>.<span class=\"title\">HTTPResponse</span>'&gt;</span></span><br><span class=\"line\"><span class=\"class\"># 返回 <span class=\"title\">HTTPResponse</span> 类型数据</span></span><br></pre></td></tr></table></figure>\n<hr>\n<p><strong>2、实例检测某网站的编码</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> chardet</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> urllib.request</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>url = input(<span class=\"string\">'input address：'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 输入网址</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>response = urllib.request.urlopen(url)</span><br><span class=\"line\"><span class=\"comment\"># urllib.request.urlopen信息传给response</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>infor = response.read()</span><br><span class=\"line\"><span class=\"comment\"># 返回获取到的页面内容</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>encode = chardet.detect(infor)[<span class=\"string\">'encoding'</span>]</span><br><span class=\"line\">&gt;&gt;&gt;print(encode)</span><br><span class=\"line\">input address：http://www.baidu.com</span><br><span class=\"line\">utf<span class=\"number\">-8</span></span><br></pre></td></tr></table></figure>\n<hr>\n<p><strong>3、检测网站状态</strong></p>\n<p>“200”则说明网站正常</p>\n<p>“404”就说明不正常</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> urllib.request</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>response=urllib.request.urlopen(<span class=\"string\">\"http://www.baidu.com\"</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>code=response.getcode()</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(code)</span><br><span class=\"line\"><span class=\"number\">200</span></span><br></pre></td></tr></table></figure>\n\n<hr>\n<hr>\n<hr>\n<p>今天晚上一直看 LOL 直播，现在有点撑不住了，都凌晨一点半了</p>\n<p>早起还要上网课</p>\n<p>上完网课再更</p>\n","url":"/posts/24985/","min2read":2,"word4post":673,"prev_post":{"title":"Python中 pip 的安装——windows系统","url":"/posts/6732/"},"next_post":{"title":"Python安装 chardet","url":"/posts/61970/"},"toc":"","categories":[{"name":"python","path":"api/categories/python.json","url":"/categories/python/"},{"name":"爬虫","path":"api/categories/爬虫.json","url":"/categories/python/爬虫/"}],"tags":[{"name":"python","path":"api/tags/python.json","url":"/tags/python/"},{"name":"爬虫","path":"api/tags/爬虫.json","url":"/tags/爬虫/"}]}